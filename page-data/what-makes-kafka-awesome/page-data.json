{"componentChunkName":"component---src-templates-blog-post-jsx","path":"/what-makes-kafka-awesome/","result":{"data":{"site":{"siteMetadata":{"title":"Abhishek Sah"}},"markdownRemark":{"id":"064c129c-09e7-5040-a9fc-71c2f1a1a2af","excerpt":"Kafka is one of those software that are in the foundations of most of the data-driven companies e.g. LinkedIn, Uber, Spotify, Slack, Gojek etc. Kafka solves the…","html":"<p><a href=\"https://kafka.apache.org/\">Kafka</a> is one of those software that are in the foundations of most of the data-driven companies e.g. LinkedIn, Uber, Spotify, Slack, Gojek etc. Kafka solves the problem of high throughput real-time data streaming with minimal latency. It’s flexible and lean architecture has helped companies scale massively without worrying about the quality and latency of the data pipeline. In this blog, we will go through internals of mighty Kafka and will find out what makes Kafka so awesome.</p>\n<p>Let’s begin with a subtle introduction.</p>\n<h2>What is Kafka</h2>\n<p>Kafka is a distributed streaming platform. To quote from the official website,</p>\n<p>A streaming platform has three key capabilities:</p>\n<ul>\n<li>Publish and subscribe to streams of records, similar to a message queue or enterprise messaging system.</li>\n<li>Store streams of records in a fault-tolerant durable way.</li>\n<li>Process streams of records as they occur.</li>\n</ul>\n<p>Kafka is used to build data pipelines, to move data among systems or applications. Kafka can store the data as well.</p>\n<p>By “data”, we mean any form of raw data or event that needs to be sent across applications or services. For example, user activity events(page views, button clicks, logins, sign ups, likes, comments etc.) or operational metrics such as errors in applications, crashes, system usage etc.</p>\n<p>These raw events are produced by users via their interaction with applications and kafka pipelines can be used to send(stream) them at desired places(applications/services). The consuming applications or services can decide to process this raw data in real time or store it for later processing.</p>\n<p><strong>Why do we need to stream these raw data/events in the first place?</strong></p>\n<p>Because this helps data-driven companies make efficient decisions. Companies can use this data to develop internal applications and microservices to improve their search relevance, recommendation systems, and target appropriate ads to customers etc.</p>\n<p>As the use cases grow and companies scale, the user facing applications produce more and more data. Streaming that data to various internal applications and services without compromising scale is the one of the onus of data engineering.</p>\n<p>This data can be of enormous volume. Think of the scale at which social media giants like Facebook, LinkedIn operate and storing all major events done by users on their website and mobile applications. This becomes billions of events every day.</p>\n<p>Streaming such enormous amount of data maintaining minimum latency is no simple job. Kafka is very good at this(we will see how). Moreover, Kafka gives you the ability to perform processing on the stream. One example of such real-time processing is calculating <a href=\"https://www.davemanuel.com/investor-dictionary/surge-pricing/\">surge pricing</a> in apps(like Uber).</p>\n<p>Surge pricing is calculated by taking into consideration the current demand and current supply. These two metrics are used in real-time to calculate how much surge price to add to the trip. For example, Surge price in Uber during rains in the evening.</p>\n<p>The real-time usage of log data brings several challenges. One of which is high throughput. Kafka gives the ability to perform such real-time processing with minimal latency. Kafka is scalable, distributed, supports high throughput, supports real-time consumption of data and provides a <a href=\"https://kafka.apache.org/documentation/#api\">rich set of APIs</a> to make developers life easy.</p>\n<h2>Kafka Architecture</h2>\n<p>Kafka’s architecture is fairly simple. There are a few logical concepts that you need to understand in order to deep dive into Kafka. Kafka runs on <a href=\"https://aws.amazon.com/pub-sub-messaging/\">Pub/Sub Model</a>. Which means, there are entities which produce messages and put in some designated places and there are entities which subscribe to these places.</p>\n<p><strong>Topic:</strong> Stream of messages of a particular type is called a topic. For example, a BookingLog Topic for Uber will keep all messages of trip booking type made on the Uber app.</p>\n<p><strong>Producer:</strong> The entity which produces messages to a topic. The producer application constructs the messages and sends it to Kafka to store that message in a particular topic.</p>\n<p><strong>Broker:</strong> Brokers are servers where the published messages are stored.</p>\n<p><strong>Consumer:</strong> The entity which consumes data that was put in a topic(from the Brokers). Consumers consume messages inside a topic from Broker via a bridge called Message Streams.</p>\n<p>Given these basic terminologies, you would have guessed the basic flow of data in Kafka.</p>\n<p>Producers produce messages(data) in topics. Brokers store those data. Consumers can consume data from these topics.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 590px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/86628d1bd5c7b4c66bf5da5effb8d0b0/dd507/1.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 18.91891891891892%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAECAIAAAABPYjBAAAACXBIWXMAAAsSAAALEgHS3X78AAAAuklEQVQI13WOzQqCQBSFfYgWrUIpgra9TpteLSinH6x0bfgKLYJsoY6CoUj+zIy/WNMoGW26fBzu4Z4Dl6PtvFo9P4qdgY8WOfxBMomX1U2+LXBRFCUIM6uH2WRrD1ZQECEPIC92gIYhgL2FOdc8Sp8kzTAheZ5zCCG20brSAzyVHAHAEYuuO8BHxxu7v7RmqluUZRzHYRgmScL9vm2gSnWzk4Nl3VOuvqz7ys3fX+7MMjQ3Zdcgr7/5N32Kwi2XMPMPAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Producer-Consumer\"\n        title=\"Producer-Consumer\"\n        src=\"/static/86628d1bd5c7b4c66bf5da5effb8d0b0/fcda8/1.png\"\n        srcset=\"/static/86628d1bd5c7b4c66bf5da5effb8d0b0/12f09/1.png 148w,\n/static/86628d1bd5c7b4c66bf5da5effb8d0b0/e4a3f/1.png 295w,\n/static/86628d1bd5c7b4c66bf5da5effb8d0b0/fcda8/1.png 590w,\n/static/86628d1bd5c7b4c66bf5da5effb8d0b0/efc66/1.png 885w,\n/static/86628d1bd5c7b4c66bf5da5effb8d0b0/c83ae/1.png 1180w,\n/static/86628d1bd5c7b4c66bf5da5effb8d0b0/dd507/1.png 1528w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>Topics can be of very high throughput depending on the use cases. BookingsLog alone is a very high throughput topic if you think about Uber’s scale. So to balance the load, topics are further divided into Partitions.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 586px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/2769fcc22eb4e863ad7225e9dfe04ed5/a76f4/2.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 90.54054054054053%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAASCAIAAADUsmlHAAAACXBIWXMAAAsSAAALEgHS3X78AAACHUlEQVQ4y52US08TURTH5xOY6EJjsUVi8FUlMepC4+s76MpvYCSNG12pJLpQWfgJXIB2ppQKppi4ML4SQIhQUSriRDpPKsO8q7TTed3rGfoaUUPD5Lc48z/33HvPmX+GwFt6fIwRxgREOaV6e1a71R43Z7S+WY02HSgkZMs7lRV3PWGiJLtnM2IUu32gcH1ahUqEMPHVsLso7mCajw/zhzfjSIaPkewg/ROKPYSCa9/9qB8bEU4+E09sYFQICCmwpmdEuPRqpVj2cK1naF21PKnira4jlV2ligqy+S6Xn6EZTvslW/5qIytXvOU1F9bXi20ffS85i4bzrQ1ow8lrNuxSL4YB7E9zbfa8L8VdfLki1Yq/6HYnxcUz/NFMkAsD24EeDyk9T/kuiqWWGgPTq/6F58s7HzORJLs7RITkokNiNCVA0BQ7SHbbQKF3UobvFHwq2GPBsPs/6fdD9M+bfVPFxIuFG2+W7nyQHnw2mql7wJxeN8l/HYhcvKZiB27o/sOeqGHPt8XK1Ql5A72TSmJaT0xpELTECfnKuHztvUKbdnDyj7J7fFSMJJlOKnBfGDAsECNbyt4Uu2OwAN6uHU7A7buH+O40Dw498Cd/K4eG+Y4k+2ix1LLnw3njzJgIMz8f4mxWAM6NiUBThDWns+Ll1xKYrDUw0/YVy1PXUSqubiNeLY3P5XM0AwG8gljLapYHncpNe3poa38E/BuB2D/72m7hNQAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Partition\"\n        title=\"Partition\"\n        src=\"/static/2769fcc22eb4e863ad7225e9dfe04ed5/a76f4/2.png\"\n        srcset=\"/static/2769fcc22eb4e863ad7225e9dfe04ed5/12f09/2.png 148w,\n/static/2769fcc22eb4e863ad7225e9dfe04ed5/e4a3f/2.png 295w,\n/static/2769fcc22eb4e863ad7225e9dfe04ed5/a76f4/2.png 586w\"\n        sizes=\"(max-width: 586px) 100vw, 586px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>Each broker stores one or more partitions of various topics.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 590px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/a4928c83ae4cfed322b03f1484bae121/29007/3.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 41.21621621621622%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAIAAAB2/0i6AAAACXBIWXMAAAsSAAALEgHS3X78AAABV0lEQVQY03VRz0sCQRjdv6C7RaduQp07BknHDlLQqUOXOgSeu3fv0LmCNDKlHxCu0A8UDKFTEkUQrqtW47qrTjntujszzvbNeinMx2Pgm29mvvfeKIwxypg3RNikAfgIwEUF2v4IUE9CCF8MQXYpVVxKb1EvpZEz/Rt4GqxQ5lDP9eT4f9/lwoemomEnnK6FEvpEohI61Mbj2mSiMnagxYoWnGnb3tZ9ay1vrBfMATcK5mrO2H36BN0KSM8jJ1kmRy/tvRLaL6H4s3VSJtm67VHaJO58BoVT9el0NZysAGdS+tRxNVZs9TlTPrpu9NqYu3yPZFBEbURUtKCi2fO37Qfs8yCzvm9zH9uugbsG/moR22aCMCFlN0lv885cuWksZ2uLF6/AJVWPXqGdR8yCxAKP4q9lWcq0+5wLIZMHD7jTsUwTxoEkh1IX8voFEGFZluM4g38C/AD12KTyT3EBAAAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Topic BookingLog split into 3 partitions &amp; stored on 2 brokers.\"\n        title=\"Topic BookingLog split into 3 partitions &amp; stored on 2 brokers.\"\n        src=\"/static/a4928c83ae4cfed322b03f1484bae121/fcda8/3.png\"\n        srcset=\"/static/a4928c83ae4cfed322b03f1484bae121/12f09/3.png 148w,\n/static/a4928c83ae4cfed322b03f1484bae121/e4a3f/3.png 295w,\n/static/a4928c83ae4cfed322b03f1484bae121/fcda8/3.png 590w,\n/static/a4928c83ae4cfed322b03f1484bae121/efc66/3.png 885w,\n/static/a4928c83ae4cfed322b03f1484bae121/c83ae/3.png 1180w,\n/static/a4928c83ae4cfed322b03f1484bae121/29007/3.png 1600w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>Partitions of a topic are simply Log files. Think of all the partitions of a topic as a file on the storage system of the Brokers. Depending on the usage, this partition’s(Log file’s) size can vary. It can be very large for some high throughput topics. So it is <a href=\"http://man7.org/linux/man-pages/man1/split.1.html\">split</a> into multiple smaller files, called <strong>Segment Files</strong>.</p>\n<p>A partition now logically looks like:</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 590px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/a9db5c497734c6f25476158324c2b5e8/29007/4.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 35.13513513513513%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAIAAACHqfpvAAAACXBIWXMAAAsSAAALEgHS3X78AAABfElEQVQY0x2QWU/CUBCF+6d98cHENTzof1AEAQlopQstlJ3S/XahhULZWlDBuGEUkkpwMLkP95tzZubci/X682hcSNzKybS83W4t+/Ey1oonpTscASrq5ComXN+IZN4CbPBe9EaEClfuAmI0ayM9WK/DyAWTuUcgm+3Zx+fPcYSimHal1ut7i/lieXCcK1XcAteZzd794G1vP9PtPWO8MGi2BvGkXG/2y1UXGUGDH8QSkqyOofkfvXhKNszpA2GoyK83vVRaFcQRGLCWOATT0RnJFB1BGmloghPG4SnZ5L1yzVW0cRZHJxFK032m4IjyKJ1VI+cMXAxrisEeURqBQ1LG0KCiCQiQ37JnLNdRdR/q2Xt9MHwhaEvRJoB4zrCdRxiHwTwy39bNgKDNUtWFQ7OQ1oc48Css53CVjqbvnsBVutBf5/saGmdwtNv88bliiyZBKcWSvfxav75904wOWKo6q3X4NF+StJajlGrdDX83fvBKUCqovOCF4eYPgcJLsqfHMiwAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Partition\"\n        title=\"Partition\"\n        src=\"/static/a9db5c497734c6f25476158324c2b5e8/fcda8/4.png\"\n        srcset=\"/static/a9db5c497734c6f25476158324c2b5e8/12f09/4.png 148w,\n/static/a9db5c497734c6f25476158324c2b5e8/e4a3f/4.png 295w,\n/static/a9db5c497734c6f25476158324c2b5e8/fcda8/4.png 590w,\n/static/a9db5c497734c6f25476158324c2b5e8/efc66/4.png 885w,\n/static/a9db5c497734c6f25476158324c2b5e8/c83ae/4.png 1180w,\n/static/a9db5c497734c6f25476158324c2b5e8/29007/4.png 1600w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>Partition P2 split into 4 segment FilesLet’s say Partition P2 is the set of segment files S1, S2, S3 and S4. Any new message produced to Partition P2 will be written to the last segment file(here, say, S4).</p>\n<p>This is to be noted that, at first the segment file lives in the memory of a broker. After a predefined threshold is reached, then only the segment file is flushed to the disk i.e. written on the secondary storage. There are two such predefined thresholds:</p>\n<ul>\n<li>A certain number of messages have been published from the publisher of that partition.</li>\n<li>Certain time has elapsed since last published event.</li>\n</ul>\n<p>The messages are only exposed to consumers when they are written to the disk. Messages residing in the memory of Brokers are never exposed.</p>\n<h3>Message format</h3>\n<p>Every message in Kafka is stored with an offset. This is so because the messages can be of varying size. So offset is decided by the size of the messages in the segment files.</p>\n<p>For example, Let’s say for segment file S1, three messages came from the producer which are of size 20bytes, 40 bytes and 20 bytes.</p>\n<p>Then the ordering of message in segment file with offset typically looks like the image below with offset of M1 as 0, offset of M2 as 20 and offset of M3 as 40.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 590px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/9f139a53e0efd7d5291462bf5344a922/d777c/5.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 27.027027027027025%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAIAAADKYVtkAAAACXBIWXMAAAsSAAALEgHS3X78AAAAj0lEQVQY012OUQ6EIBBDuf8BOYKJkPghgoCA+5ZGN9l+YKfTqTX3g+u6Sil6c85lotYqRSKoE5AxhnmPmfHFGHvv53m21ljjkwKXgZctWRh+x/iY932Hs8MtEkJ4DYhcEtcmDKkMRKIqWwd/tSEpJTlV8HvMx1q7rutxHKqKdVmW8UCd+TOlnHNq4b3ftu0DuWAkISWdWO8AAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"A typical order of messages inside a segment file.\"\n        title=\"A typical order of messages inside a segment file.\"\n        src=\"/static/9f139a53e0efd7d5291462bf5344a922/fcda8/5.png\"\n        srcset=\"/static/9f139a53e0efd7d5291462bf5344a922/12f09/5.png 148w,\n/static/9f139a53e0efd7d5291462bf5344a922/e4a3f/5.png 295w,\n/static/9f139a53e0efd7d5291462bf5344a922/fcda8/5.png 590w,\n/static/9f139a53e0efd7d5291462bf5344a922/efc66/5.png 885w,\n/static/9f139a53e0efd7d5291462bf5344a922/c83ae/5.png 1180w,\n/static/9f139a53e0efd7d5291462bf5344a922/d777c/5.png 1555w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>Here you can see the offsets are in increasing order but they are not consecutive.</p>\n<p>Traditionally, message queue systems (such as RabbitMQ) use message ID instead of offset. The message ID does the one-to-one mapping of Message’s location on disk. This allows the user to do random indexing of the messages. Random access to messages is a <a href=\"https://www.geeksforgeeks.org/difference-between-seek-time-and-rotational-latency-in-disk-scheduling/\">seek</a> intensive operation. This is a costly IO operation affecting latency. Kafka avoids using message IDs.</p>\n<p>Offsets are also used as consumers acknowledgements. If a consumer acknowledges an offset x, it is assumed that the consumer has consumed all messages with offset &#x3C; x.</p>\n<h3>Managing partitions on the broker</h3>\n<p>It’s time to understand how brokers store and manage any partition. As we have understood, partitions are a set of segment files. Every segment file starts with some message. Every message is identified with a message offset.</p>\n<p>Brokers store a sorted table in memory which basically keeps the first offset of each segment file.</p>\n<p>Let’s see it this way. Let’s say for partition P1, there are 5 segment files(S1, S2, S3, S4 and S5). The first message in S1 has offset 0. Likewise, first messages of files S2, S3, S4 and S5 have offsets 1000, 2000, 2500 and 2700 respectively.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 306px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/79d1bd16b9ce30ab7ade56a2422aabb0/98b92/6.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 138.51351351351352%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAcCAIAAADuuAg3AAAACXBIWXMAAAsSAAALEgHS3X78AAACL0lEQVQ4y42USY/aQBCF/f+FRACJU+CAOMEBInFCCCQOCMQqdgggCOuw70vY8uHOgI3tTN6hVe6qLr96XdVSKBRqt9v1ev2nHlqtlu5+o9FIp9NSs9m83++32+2uh+PxqN0UwfP5XOKfWJfL5abA9Xplc71eOxyO4XCIzc6bdzweS3AQPm3u0+kUDAaXy+UbNWFPJhOpUqmIuN8anM9n4ljf9gnmZzCSwuFwt9ul8pYaTRkII4w3Fxpns1kJt5Fgok4jwabTqY5gov5UKhWJRH7I8Pl8+/3+me4lmNHhfD7v9/tR+7uM7Xarc1hXbQGlclraD7Wj0Si6dTqdX2ogSecTfCoDsHu9XqFQkEqlEpkOh8NRjScXUYvSRTB0+v2+Dm3BqlqtohnpKT6XyymZv2jXajUsfFcF2HG5XHa73WazmUwms9lMqwpd8bL+FUz3nvmkNrT4kIGhpTabzaR4PM58jEajDzUWi8XsEwQoXQTDGcpSIpEgjq2xGhwQ5+cylC6CaS8aRIe2sEVGRoqThOrTNhLM7XajltPp/CZjtVq9CUZqQ8G4nmKxmEwmmZ5MJqO9qsefuczNZvOs7Qk6Ybfbse5lKF0EUw6DKcViMUoaDAZDNRhyelCsQBmADWdekX/NsxFetHUfQHZISmNSMAHlcplmfvb51yPp9XoDgYDH47FarRaLRcyzyPvqbaOnF6lFS9RlCLX/989f1vx4wyiMidFeFb5nb2Nrr4rX4g+3Axv3rYJ7XgAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Broker&#39;s in-memory table\"\n        title=\"Broker&#39;s in-memory table\"\n        src=\"/static/79d1bd16b9ce30ab7ade56a2422aabb0/98b92/6.png\"\n        srcset=\"/static/79d1bd16b9ce30ab7ade56a2422aabb0/12f09/6.png 148w,\n/static/79d1bd16b9ce30ab7ade56a2422aabb0/e4a3f/6.png 295w,\n/static/79d1bd16b9ce30ab7ade56a2422aabb0/98b92/6.png 306w\"\n        sizes=\"(max-width: 306px) 100vw, 306px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>The broker will store an in-memory table which keeps the offset of the first message in each segment file. Here : 0, 1000, 2000, 2500, 2700</p>\n<p>Table of starting offset of each segment fileAny new message which comes, if stored in S5, won’t affect this table. As soon as, a new segment file appears, this table will be updated with the offset of the first message in the new segment file.</p>\n<p>This table is used to find the segment file which contains the offset asked by the consumer.</p>\n<h3>Consumption of messages</h3>\n<p>Consuming messages is fairly simple. The series of events are:</p>\n<ul>\n<li>Consumers send a pull request to brokers. In this request, there are two things: Consumers specify the <em>offset to begin with</em>, and an <em>acceptable number of bytes in the message</em>.</li>\n<li>Broker on receiving the offset to begin calculates which segment file has the message with asked offset. Broker searches the above table for the address of the segment file to which the message belongs.</li>\n<li>Broker fetches the data from that segment file and sends to the consumer.</li>\n<li>The consumer consumes this data.</li>\n<li>The consumer sends the next offset in the new pull request.</li>\n</ul>\n<h3>Efficiency of Kafka</h3>\n<p>Kafka is considered the best real-time streaming platform out there. The efficiency speaks for itself in various benchmarking tests. This efficiency results from several design decisions(rather unconventional).</p>\n<h4>Storage Efficiency</h4>\n<p>The first one is the use of offsets instead of message-ids which saves the cost of seek intensive random accesses. On top of that, keeping an index of the offsets of starting message in each segment file makes consumption from a partition fairly efficient.</p>\n<p>The second unconventional choice that we see in Kafka is avoiding any caching in Kafka Layer. Kafka avoids caching every message in memory at the process level. Instead, it relies on the underlying file system cache. This offers multiple benefits.</p>\n<p>First, it avoids double buffering. Modern operating heavily use main memory for disk caching. A modern OS will happily divert all free memory to disk caching with little performance penalty when the memory is reclaimed. All disk reads and writes will go through this unified cache. So even if a process maintains an in-process cache of the data, this data will likely be duplicated in OS page cache, effectively storing everything twice. Although there could be a debate on when and how to process level caching is useful. Read this <a href=\"https://queue.acm.org/detail.cfm?id=1563874\">ACM article</a> for a thorough analysis.</p>\n<p>Secondly, this cache(the file system cache) will stay warm even if the broker service is restarted, whereas the in-process cache will need to be rebuilt in memory.</p>\n<p>The third benefit is that no cache at process level means, less overhead in Garbage collection, giving efficiency in VM based languages.</p>\n<p>The fourth benefit comes from the use of traditional caching heuristics like write-through cache. Since both consumer and producer access the segment files sequentially, normal caching heuristics present in most OS works fine.</p>\n<h4>Network Efficiency</h4>\n<p>Consumption of messages from the File system involves fetching message from secondary storage and sending all the way to network sockets. This typically involves reading data from the storage to page cache, copying page cache to application buffer, copying application buffer to kernel buffer and finally sending kernel buffer to a socket. This involves 4 data copying calls and 2 system calls.</p>\n<p>Kafka uses the <a href=\"http://man7.org/linux/man-pages/man2/sendfile.2.html\">sendfile API</a> available in Linux which does the same thing in 2 data copying calls and 1 system call. This optimized API results in the fast consumption of data.</p>\n<h4>Broker’s design efficiency</h4>\n<p>Kafka Brokers are stateless. It means that a broker doesn’t know which consumer has consumed till what offset. The consumer itself keeps track of the offset. It reduces overhead from the Broker. But there are cons as well. Deleting messages becomes difficult since the broker doesn’t know if all consumers have consumed that message. For this, Kafka gives a time-based SLA where retention policy can be configured for brokers.</p>\n<p>Brokers being stateless gives a side benefit to consumers to deliberately choose to rewind back to an old offset and re-consume(if the messages have not exceeded retention period, of course). Though, it is a violation of queue but has proved as an essential feature. For example, if consumer application feeding on data from Kafka has some bugs, then the data can be replayed after the bug has been resolved.</p>\n<h3>Distributed Consensus</h3>\n<p>Let’s see how producers and consumers behave in a distributed setting.</p>\n<p>The producers produce data to a topic stored in Brokers and consumers consumer from these topics. Producers need to decide which partition to produce data. A partition can be randomly selected by the producer or by using a partitioning function.</p>\n<p>Consumers to a topic are put in a group called “Consumer Group”. Each message m of Topic T is delivered to only one consumer in the consumer group. At any time, all messages from one single partition are consumed by a single consumer. Different consumer groups independently consume messages from topics. No coordination is required among them. But within a consumer group, coordination is required.</p>\n<p>The leader inside a consumer group is decided by a separate entity called <a href=\"https://zookeeper.apache.org/\">Zookeeper</a>. Kafka uses Zookeeper as a configuration store.\nZookeeper does these 3 things for Kafka.</p>\n<ul>\n<li>Detecting the addition and removal of brokers and consumers</li>\n<li>Triggering re-balance process in each consumer when the above event occurs</li>\n<li>Maintaining track of consumed offset of each partition</li>\n</ul>\n<p>Re-balancing, whenever required, is taken care of by zookeeper by running a re-balancing algorithm.</p>\n<p>Kafka uses Zookeeper to maintain 4 types of registries(config stores)for various purposes. Let’s quickly see what each registry stores.</p>\n<p><strong>Broker registry:</strong> Stores information about brokers. It stores the host and port of the broker and the set of topics and partitions stored in the broker.</p>\n<p><strong>Consumer Registry:</strong> Stores consumer group of each consumer and set of topics each consumer is subscribing.</p>\n<p><strong>Ownership Registry:</strong> Stores one path for every subscribed partition and the id of the consumer currently consuming for this\npartition. This consumer is said to own the partition.</p>\n<p><strong>Offset Registry:</strong> Stores for each partition, the offset of the last consumed message.</p>\n<p>The first three registries are <strong>ephemeral</strong> i,e. if the creating client is gone, these path created in corresponding registries is removed from by zookeeper server. Offset registry is <strong>persistent</strong>.</p>\n<p>Each consumer has a watcher on both Consumer registry and Broker registry. Whenever broker set changes or consumer group changes or the startup of a consumer happens the watcher notifies consumers to initiate a re-balancing algorithm process. This is to determine new subsets of partitions it should subscribe from. To learn more about the re-balancing algorithm, read this manual.</p>\n<h3>Delivery Guarantee</h3>\n<p>Kafka only guarantees at least once delivery. By design, they didn’t want to go for the exactly-once guarantee, because that would have retired efforts in two-phase commits which were not necessary requirement for Kafka.</p>\n<p>Kafka also doesn’t guarantee to order of the messages. Since messages go to different partitions, can be consumed from different partitions as per the consumers want. So there is no inherent ordering of messages by design in Kafka. Consumers itself will have to take care of the ordering of the messages.</p>\n<p>Kafka also takes care of the data corruption by giving Cyclic redundancy check at the message level. This allows you to check network error.</p>\n<hr>\n<p>If you have been following up this far, thanks for reading. This blog is inspired by the <a href=\"https://www.microsoft.com/en-us/research/wp-content/uploads/2017/09/Kafka.pdf\">Kafka white paper</a>. I would suggest the readers explore <a href=\"https://cwiki.apache.org/confluence/display/KAFKA/Kafka+papers+and+presentations\">this wiki</a> to learn some more detailed concepts about Kafka.</p>\n<p>Feel free to comment below your thoughts or connect with me on <a href=\"https://twitter.com/whoAbhishekSah\">Twitter</a> for any conversations on this blog.</p>","frontmatter":{"title":"What makes Kafka awesome?","date":"May 07, 2020","description":"Kafka"}}},"pageContext":{"slug":"/what-makes-kafka-awesome/","previous":{"fields":{"slug":"/no-silver-buttes-indeed/"},"frontmatter":{"title":"No Silver Bullets indeed!"}},"next":{"fields":{"slug":"/kafka-scaling/"},"frontmatter":{"title":"Horizontally scaling up a Kafka cluster "}}}}}